---
title: "[ML Q&AI - 1] Embeddings, Latent Space, and Representations"
mathjax: false
toc: true
categories:
    - machine-learning
tags:
    - embedding
date: 2025-08-14 14:21:43
---

# 总结

[Chapter 1: Embeddings, Latent Space, and Representations](https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/)

`Representation`：是最原始的数据编码后的任意形式，可以是原始值、离散编码、连续编码等；广义术语，不特指具体的方法。

`Embeddings` `Embedding vectors`：是输入数据经过**映射/压缩/降维**后的表示，特点是：

- **降维性**：维度通常远低于原始输入（如从1万维One-Hot→300维向量）。
- **相似性保持**：语义/结构相似的输入在嵌入空间中距离相近（如词向量中“猫”≈“狗”≫“汽车”）

`Latent space`：就是 `Embedding vectors` 张成的**低维子空间**，是模型学到的特征空间。

---

# 拓展学习

[What Are Word Embeddings](https://www.youtube.com/watch?v=hVM8qGRTaOA)
[什么是Embeddings](https://www.bilibili.com/video/BV188TVzREP7/)

顶级理解！推荐！

[大模型靠啥理解文字？通俗解释：词嵌入embedding](https://www.bilibili.com/video/BV1bfoQYCEHC)